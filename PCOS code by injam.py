# -*- coding: utf-8 -*-
"""First task for R.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aFxYopi0hFSFY5wKDiM0HI98FSsiufMF
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_excel("/content/drive/MyDrive/Zahid sir Assignment/Dataset with disease data.xlsx")

df.head()

df.describe()

df.info()

df.isnull().sum().sort_values(ascending=False).head()

df=df.drop(['Unnamed: 44'], axis = 1)
df=df.drop(['Sl. No'], axis = 1)
df=df.drop(['Patient File No.'], axis = 1)
#df=df.drop(['  I   beta-HCG(mIU/mL)'], axis = 1)
df=df.drop(['II    beta-HCG(mIU/mL)'], axis = 1)

df.columns

df=df.drop(['AMH(ng/mL)'], axis = 1)

df.isnull().sum().sort_values(ascending=False).head()

df['Marraige Status (Yrs)'] = df['Marraige Status (Yrs)'].fillna(method="ffill")
df['Fast food (Y/N)'] = df['Fast food (Y/N)'].fillna(method="ffill")

df.shape

df=df.drop(['Waist:Hip Ratio'], axis = 1)
df=df.drop(['FSH/LH'], axis = 1)

df['BMI'].fillna(df['BMI'].median(),inplace=True)

df.isnull().sum().sort_values(ascending=False).head()

"""**Visulization**"""

mean_abs_diff = np.sum(np.abs(df-np.mean(df,axis=0)),axis=0)/df.shape[0]
plt.bar(np.arange(df.shape[1]),mean_abs_diff,color='teal')

color = ["teal", "plum"]
features = ["Follicle No. (L)","Follicle No. (R)"]
for i in features:
    sns.swarmplot(x=df["PCOS (Y/N)"], y=df[i], color="black", alpha=0.5 )
    sns.boxenplot(x=df["PCOS (Y/N)"], y=df[i], palette=color)
    plt.show()

"""The number of follicles in women with PCOS is higher, as expected. And are unequal as well."""

features = ["Avg. F size (L) (mm)","Avg. F size (R) (mm)"]
for i in features:
    sns.swarmplot(x=df["PCOS (Y/N)"], y=df[i], color="black", alpha=0.5 )
    sns.boxenplot(x=df["PCOS (Y/N)"], y=df[i], palette=color)
    plt.show()

features = ['Hip(inch)', 'Waist(inch)']
for i in features:
    sns.swarmplot(x=df["PCOS (Y/N)"], y=df[i], color="black", alpha=0.5 )
    sns.boxenplot(x=df["PCOS (Y/N)"], y=df[i], palette=color)
    plt.show()

"""Selecting Target and feature value"""

x = df.drop(['PCOS (Y/N)'],axis=1)
y = df['PCOS (Y/N)']

x

"""Normalization"""

from sklearn.preprocessing import MinMaxScaler
sscaler = MinMaxScaler() #helps us scale the dataset. This makes it easy for the model to train
cols = x.columns
y_scaled = sscaler.fit_transform(x)
x_scaled = pd.DataFrame(y_scaled, columns = cols)
x_scaled

"""Train_test_split"""

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x_scaled,y,test_size=0.3,random_state=1)

x_train

"""Logistic regression"""

from sklearn.linear_model import LogisticRegression
logisModel = LogisticRegression()
#And now fit the model into x_train and y_train
logisModel.fit(x_train,y_train)

y_pred = logisModel.predict(x_test)

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

print(confusion_matrix(y_test,y_pred))

logisModel.score(x_test,y_test)

"""**Random forest**"""

from sklearn.ensemble import RandomForestClassifier
classifier= RandomForestClassifier(n_estimators= 28, criterion="entropy")  
classifier.fit(x_train, y_train)

"""n_estimators= The required number of trees in the Random Forest. The default value is 10. We can choose any number but need to take care of the overfitting issue.
criterion= It is a function to analyze the accuracy of the split. Here we have taken "entropy" for the information gain.
"""

y_pred= classifier.predict(x_test)

from sklearn.metrics import confusion_matrix  
cm= confusion_matrix(y_test, y_pred)

cm

classifier.score(x_test,y_test)

"""**Decition Tree**"""

from sklearn.tree import DecisionTreeClassifier  
classifi= DecisionTreeClassifier(criterion='entropy', random_state=1)  
classifi.fit(x_train, y_train)

y_pred= classifi.predict(x_test)

from sklearn.metrics import confusion_matrix  
cm= confusion_matrix(y_test, y_pred)  
cm

classifi.score(x_test,y_test)

"""Naive Bayes"""

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(x_train, y_train)

pred = gnb.predict(x_test)

from sklearn.metrics import classification_report,confusion_matrix
print(confusion_matrix(y_test,pred))

gnb.score(x_test,y_test)

from sklearn.datasets import make_classification
from xgboost import XGBClassifier
# define dataset
# define the model
model = XGBClassifier()
# fit the model on the whole dataset
model.fit(x_train, y_train)

model.score(x_test,y_test)